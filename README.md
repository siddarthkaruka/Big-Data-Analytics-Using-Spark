# Big-Data-Analytics-Using-Spark
This contains all the exercise files from the Big Data Analytics Using Spark course (DSE230x) at UCSD 


# From the course website

Welcome to Big Data Analytics using Spark!
We are delighted to welcome you to the fourth course in the MicroMasters in Data Science: Big Data Analytics using Spark.This course teaches you how to perform statistical analysis of very large datasets that do not fit on a single computer. You will learn some of the most popular tools for performing this type of analysis: apache spark, XGBoost and TensorFlow. You will learn how to use these tools through Jupyter Notebooks and experience the power of combining narrative, code and graphics to create convincing analytical documents.


**Instructor:**\
Yoav Freund, Professor of Electrical and Computer Engineering, UC San Diego

**Prerequisites:**\
The most important prerequisites for this course are:
- The ability to program in Python and to use Jupyter notebooks. This can be obtained by taking the course DSE 200x, Python for Data Science.
- Probability and statistics. This can be obtained by taking the course DSE 210x, Probability and Statistics using Python.
- Machine Learning: This can be obtained by taking the course DSE 220x, Machine learning Fundamentals.

**Learning objectives:**\
This course has two main goals: The first is introduction to using large scale data analysis frameworks (Spark, XGBoost and TensorFlow). This includes the underlying computer architecture and the programming abstractions. The second is to combine methods from statistics and machine learning to perform large scale analysis, identify statistically significant pattern and visualize statistical summaries.
 
**Course Outline:**\
This is a ten-week course.

**Topics:**\
- Memory Hierarchy, latency vs. throughput.
- Spark Basics
- Dataframes and SQL
- PCA and weather analysis
- K-means and intrinsic dimensions
- Decision trees, boosting, and random forests
- Neural Networks and TensorFlow
